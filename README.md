# Time Series and Foundation Modeling Papers
A collection of research papers and notes on time series analysis. 

| Author            | Title                                                | Proceeding   | KeyWords | Link                                     |
|-------------------|------------------------------------------------------|--------------|----------|------------------------------------------|
| Mingtian Tan, et al. | Are Language Models Actually Useful for Time Series Forecasting?  | NeurIPS 2024 | LLM | https://arxiv.org/abs/2406.16964 |
| Xin Liu, et al. | Large Language Models are Few-Shot Health Learners  |  | LLM, Health | https://arxiv.org/abs/2305.15525 |
| Yong Liu, et al. | AutoTimes: Autoregressive Time Series Forecasters via Large Language Models | NeurIPS 2024 | LLM, Forecast, Autoregressive | https://arxiv.org/abs/2402.02370 |
| H. Kamarthi and B.A.Prakash | Large Pre-trained time series models for cross-domain Time series analysis tasks | NeurIPS 2024 | LLM, SSL, Cross-Domain | https://arxiv.org/abs/2311.11413 |

## Transformer-based
| Author            | Title                                                | Proceeding   | KeyWords | Link                                     |
|-------------------|------------------------------------------------------|--------------|----------|------------------------------------------|
| Yihe Wang, et al. | Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification | NeurIPS 2024 | Transformer, Medical, Classification | https://arxiv.org/abs/2405.19363 |

## with MAE
| Author            | Title                                                | Proceeding   | KeyWords | Link                                     |
|-------------------|------------------------------------------------------|--------------|----------|------------------------------------------|
| Zhe Li, et al. | Ti-MAE: Self-Supervised Masked Time Series Autoencoders  |   | MAE, SSL | https://arxiv.org/abs/2301.08871 |
